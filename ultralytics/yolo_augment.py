# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
yoloæ£€æµ‹æ¡†/åˆ†å‰²æ¡†æ•°æ®å¢å¼ºè„šæœ¬ï¼Œå®ç°æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€å·¦å³ç¿»è½¬ã€äº®åº¦ã€é¥±å’Œåº¦ç­‰ä¸€ç³»åˆ—éšæœºæ··åˆå¢å¼ºï¼Œé»˜è®¤ä½¿æ•°æ®é›†æ‰©å……åˆ°åŸæœ‰çš„3å€å·¦å³ã€‚
The YOLO detection box / mask data augmentation script implements a series of random mixed enhancements
such as rotation, translation, scaling, horizontal flipping, brightness, and saturation,
and by default expands the dataset to about three times its original size.

usage:
    python yolo_augment.py \
                --input path/to/input \
                --output path/to/output \
                [--num 2]

folder:
    .
    â””â”€â”€ PATH_TO_input_folder
        â”œâ”€â”€ images
            â”œâ”€â”€ 1.jpg
            â”œâ”€â”€ 2.jpg
            â””â”€â”€ ...
        â”œâ”€â”€ labels
            â”œâ”€â”€ 1.txt
            â”œâ”€â”€ 2.txt
            â””â”€â”€ ...
    .
    â””â”€â”€ PATH_TO_output_folder
        â”œâ”€â”€ images
        â”œâ”€â”€ labels

"""

import os
import cv2
import shutil
import argparse
import numpy as np
import albumentations as A
from tqdm import tqdm


def get_augmentation_pipelines():
    """å®šä¹‰å¹¶è¿”å›ç”¨äºæ£€æµ‹å’Œåˆ†å‰²çš„ä¸¤ç§å¢å¼ºç®¡é“"""

    # å…±äº«çš„å˜æ¢é€»è¾‘
    shared_transforms = [
        A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2, p=0.75),
        A.RandomBrightnessContrast(p=0.7),
        A.HorizontalFlip(p=0.7),
        A.Affine(
            scale=(0.8, 1.2),
            translate_percent=(-0.1, 0.1),
            rotate=(-30, 30),
            p=0.75
        ),
    ]

    # ç”¨äºæ£€æµ‹æ¡†çš„ç®¡é“
    detection_pipeline = A.Compose(
        shared_transforms,
        bbox_params=A.BboxParams(
            format='yolo',
            label_fields=['class_labels']
        )
    )

    # ç”¨äºåˆ†å‰²çš„ç®¡é“ï¼ˆä¸éœ€è¦bbox_paramsï¼‰
    segmentation_pipeline = A.Compose(shared_transforms)

    return detection_pipeline, segmentation_pipeline


def augment_dataset(input_dir, output_dir, num_aug_per_image=2):
    """
    å¯¹æ•°æ®é›†è¿›è¡Œæ™ºèƒ½æ•°æ®å¢å¼ºï¼Œè‡ªåŠ¨è¯†åˆ«æ ‡ç­¾ç±»å‹ã€‚
    """
    # 1. è®¾ç½®è·¯å¾„
    input_images_dir = os.path.join(input_dir, 'images')
    input_labels_dir = os.path.join(input_dir, 'labels')
    output_images_dir = os.path.join(output_dir, 'images')
    output_labels_dir = os.path.join(output_dir, 'labels')

    # 2. åˆ›å»ºè¾“å‡ºç›®å½•å¹¶å¤åˆ¶åŸå§‹æ–‡ä»¶
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    print("Step 1: æ­£åœ¨å¤åˆ¶åŸå§‹æ–‡ä»¶...")
    for subdir, output_subdir in [(input_images_dir, output_images_dir), (input_labels_dir, output_labels_dir)]:
        if not os.path.exists(subdir):
            print(f"Warning: Directory not found, skipping: {subdir}")
            continue
        for filename in tqdm(os.listdir(subdir), desc=f"å¤åˆ¶ {os.path.basename(subdir)}"):
            shutil.copy2(os.path.join(subdir, filename), os.path.join(output_subdir, filename))
    print("åŸå§‹æ–‡ä»¶å¤åˆ¶å®Œæˆï¼\n")

    # 3. è·å–å¢å¼ºç®¡é“å’Œå›¾åƒåˆ—è¡¨
    detection_transform, segmentation_transform = get_augmentation_pipelines()
    image_files = [f for f in os.listdir(input_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    detected_format = None  # ç”¨äºå­˜å‚¨æ£€æµ‹åˆ°çš„æ ¼å¼

    print(f"Step 2: å¼€å§‹ä¸º {len(image_files)} å¼ å›¾åƒç”Ÿæˆå¢å¼ºæ•°æ®...")
    # 4. éå†æ‰€æœ‰å›¾åƒè¿›è¡Œå¤„ç†
    for image_filename in tqdm(image_files, desc="ç”Ÿæˆå¢å¼ºæ•°æ®ä¸­"):
        base_name, ext = os.path.splitext(image_filename)
        image_path = os.path.join(input_images_dir, image_filename)
        label_path = os.path.join(input_labels_dir, base_name + '.txt')

        if not os.path.exists(label_path):
            continue

        # --- è‡ªåŠ¨æ ¼å¼æ£€æµ‹ ---
        current_format = None
        with open(label_path, 'r') as f:
            first_line = f.readline().strip()
            if first_line:
                parts = first_line.split()
                num_parts = len(parts)
                if num_parts == 5:
                    current_format = 'detection'
                elif num_parts > 5 and num_parts % 2 != 0:
                    current_format = 'segmentation'

        if not current_format:
            print(f"\nè­¦å‘Šï¼šæ— æ³•è¯†åˆ«æ ‡ç­¾æ ¼å¼æˆ–æ–‡ä»¶ä¸ºç©ºï¼Œå·²è·³è¿‡ {label_path}")
            continue

        if detected_format is None:
            detected_format = current_format
            print(f"\n--- æ•°æ®é›†æ ¼å¼è‡ªåŠ¨æ£€æµ‹ä¸º: {detected_format.upper()} ---")
        elif detected_format != current_format:
            print(f"\nè­¦å‘Šï¼šæ•°æ®é›†ä¸­æ ‡ç­¾æ ¼å¼ä¸ä¸€è‡´ï¼Œå·²è·³è¿‡ {label_path}")
            continue

        # --- è¯»å–æ•°æ®å’Œå¢å¼º ---
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        for i in range(num_aug_per_image):
            aug_base_name = f"{base_name}_aug_{i}"

            try:
                if detected_format == 'detection':
                    # --- æ£€æµ‹æ¡†å¤„ç†æµç¨‹ ---
                    bboxes, class_labels = [], []
                    with open(label_path, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            class_labels.append(int(parts[0]))
                            bboxes.append([float(p) for p in parts[1:]])

                    augmented = detection_transform(image=image_rgb, bboxes=bboxes, class_labels=class_labels)

                    if not augmented['bboxes']: continue

                    aug_image_path = os.path.join(output_images_dir, aug_base_name + ext)
                    cv2.imwrite(aug_image_path, cv2.cvtColor(augmented['image'], cv2.COLOR_RGB2BGR))

                    aug_label_path = os.path.join(output_labels_dir, aug_base_name + '.txt')
                    with open(aug_label_path, 'w') as f:
                        for bbox, class_id in zip(augmented['bboxes'], augmented['class_labels']):
                            f.write(f"{int(class_id)} {' '.join(f'{c:.6f}' for c in bbox)}\n")

                elif detected_format == 'segmentation':
                    # --- åˆ†å‰²å¤„ç†æµç¨‹ ---
                    h, w = image_rgb.shape[:2]
                    masks, class_ids = [], []
                    with open(label_path, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            class_ids.append(int(parts[0]))
                            polygon_norm = np.array([float(p) for p in parts[1:]]).reshape(-1, 2)
                            polygon_abs = polygon_norm * np.array([w, h])
                            mask = np.zeros((h, w), dtype=np.uint8)
                            cv2.fillPoly(mask, [polygon_abs.astype(np.int32)], 1)
                            masks.append(mask)

                    augmented = segmentation_transform(image=image_rgb, masks=masks)
                    new_h, new_w = augmented['image'].shape[:2]

                    aug_image_path = os.path.join(output_images_dir, aug_base_name + ext)
                    cv2.imwrite(aug_image_path, cv2.cvtColor(augmented['image'], cv2.COLOR_RGB2BGR))

                    aug_label_path = os.path.join(output_labels_dir, aug_base_name + '.txt')
                    yolo_labels = []
                    for class_id, aug_mask in zip(class_ids, augmented['masks']):
                        contours, _ = cv2.findContours(aug_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        if contours:
                            contour = max(contours, key=cv2.contourArea)
                            if contour.shape[0] >= 3:
                                contour_norm = contour.astype(np.float32).squeeze(1)
                                contour_norm[:, 0] /= new_w
                                contour_norm[:, 1] /= new_h
                                yolo_line = f"{class_id} " + " ".join([f"{c:.6f}" for c in contour_norm.flatten()])
                                yolo_labels.append(yolo_line)

                    if yolo_labels:
                        with open(aug_label_path, 'w') as f:
                            f.write("\n".join(yolo_labels))
            except Exception as e:
                print(f"\nå¤„ç† {image_filename} æ—¶å‘ç”Ÿé”™è¯¯ (å¢å¼ºç‰ˆæœ¬ {i}): {e}")

    print("\næ•°æ®å¢å¼ºæµç¨‹å…¨éƒ¨å®Œæˆï¼")
    print(f"ç»“æœå·²ä¿å­˜åœ¨: {os.path.abspath(output_dir)}")


def main():
    parser = argparse.ArgumentParser(description="Intelligent YOLO Detection/Segmentation Data Augmentation Script")
    parser.add_argument('--input', type=str, required=True,
                        help='Path to the input dataset directory.')
    parser.add_argument('--output', type=str, required=True,
                        help='Path to the directory to save the augmented dataset.')
    parser.add_argument('--num', type=int, default=2,
                        help='Number of augmented versions to generate per original image.')

    args = parser.parse_args()
    augment_dataset(args.input, args.output, args.num)


if __name__ == "__main__":
    main()