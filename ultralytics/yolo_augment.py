# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
yoloæ£€æµ‹æ¡†æ•°æ®å¢å¼ºè„šæœ¬ï¼Œå®ç°æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€å·¦å³ç¿»è½¬ã€äº®åº¦ã€é¥±å’Œåº¦ç­‰ä¸€ç³»åˆ—éšæœºæ··åˆå¢å¼ºï¼Œé»˜è®¤ä½¿æ•°æ®é›†æ‰©å……åˆ°åŸæœ‰çš„3å€å·¦å³ã€‚
The YOLO detection box data augmentation script implements a series of random mixed enhancements
such as rotation, translation, scaling, horizontal flipping, brightness, and saturation,
and by default expands the dataset to about three times its original size.

usage:
    python yolo_augment.py \
                --input path/to/input \
                --output path/to/output \
                [--num 2]

folder:
    .
    â””â”€â”€ PATH_TO_input_folder
        â”œâ”€â”€ images
            â”œâ”€â”€ 1.jpg
            â”œâ”€â”€ 2.jpg
            â””â”€â”€ ...
        â”œâ”€â”€ labels
            â”œâ”€â”€ 1.txt
            â”œâ”€â”€ 2.txt
            â””â”€â”€ ...
    .
    â””â”€â”€ PATH_TO_output_folder
        â”œâ”€â”€ images
        â”œâ”€â”€ labels

"""

import os
import cv2
import shutil
import argparse
import albumentations as A
from tqdm import tqdm


def get_augmentation_pipeline():
    """
    å®šä¹‰å¹¶è¿”å›ä¸€ä¸ªæ•°æ®å¢å¼ºæµç¨‹ã€‚
    Albumentations å¯ä»¥åŒæ—¶è½¬æ¢å›¾åƒå’Œå…¶å¯¹åº”çš„è¾¹ç•Œæ¡†ã€‚
    """
    return A.Compose([
        # é¢œè‰²å’Œäº®åº¦å˜æ¢
        A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2, p=0.75),
        A.RandomBrightnessContrast(p=0.5),

        # å‡ ä½•å˜æ¢
        A.HorizontalFlip(p=0.8),
        # Affine å˜æ¢é›†æˆäº†å¹³ç§»ã€ç¼©æ”¾ï¼ˆæ‹‰ä¼¸ï¼‰å’Œæ—‹è½¬
        A.Affine(
            scale=(0.8, 1.2),  # å›¾åƒç¼©æ”¾èŒƒå›´ï¼ˆ80% - 120%ï¼‰
            translate_percent=(-0.1, 0.1),  # å¹³ç§»èŒƒå›´
            rotate=(-30, 30),  # æ—‹è½¬èŒƒå›´ (-30 åˆ° 30 åº¦)
            p=0.75
        ),
    ], bbox_params=A.BboxParams(
        format='yolo',  # å…³é”®ï¼æŒ‡å®šè¾¹ç•Œæ¡†æ˜¯ YOLO æ ¼å¼
        label_fields=['class_labels']  # å…³è”ç±»åˆ«æ ‡ç­¾
    ))


def augment_dataset(input_dir, output_dir, num_aug_per_image=2):
    """
    å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œæ•°æ®å¢å¼ºã€‚

    Args:
        input_dir (str): è¾“å…¥æ•°æ®é›†çš„è·¯å¾„ã€‚
        output_dir (str): è¾“å‡ºå¢å¼ºåæ•°æ®é›†çš„è·¯å¾„ã€‚
        num_aug_per_image (int): æ¯å¼ åŸå§‹å›¾åƒè¦ç”Ÿæˆçš„å¢å¼ºç‰ˆæœ¬æ•°é‡ã€‚
    """
    # 1. è®¾ç½®è·¯å¾„
    input_images_dir = os.path.join(input_dir, 'images')
    input_labels_dir = os.path.join(input_dir, 'labels')
    output_images_dir = os.path.join(output_dir, 'images')
    output_labels_dir = os.path.join(output_dir, 'labels')

    # 2. åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    print("Step 1: æ­£åœ¨å¤åˆ¶åŸå§‹æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•...")
    # 3. å¤åˆ¶åŸå§‹æ–‡ä»¶
    for subdir, output_subdir in [(input_images_dir, output_images_dir), (input_labels_dir, output_labels_dir)]:
        for filename in tqdm(os.listdir(subdir), desc=f"å¤åˆ¶ {os.path.basename(subdir)}"):
            shutil.copy2(os.path.join(subdir, filename), os.path.join(output_subdir, filename))
    print("åŸå§‹æ–‡ä»¶å¤åˆ¶å®Œæˆï¼\n")

    # 4. è·å–æ•°æ®å¢å¼ºç®¡é“å’Œå›¾åƒåˆ—è¡¨
    transform = get_augmentation_pipeline()
    image_files = [f for f in os.listdir(input_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    print(f"Step 2: å¼€å§‹ä¸º {len(image_files)} å¼ å›¾åƒç”Ÿæˆå¢å¼ºæ•°æ®...")
    # 5. å¾ªç¯å¤„ç†æ¯å¼ å›¾åƒ
    for image_filename in tqdm(image_files, desc="ç”Ÿæˆå¢å¼ºæ•°æ®ä¸­"):
        base_name, ext = os.path.splitext(image_filename)
        image_path = os.path.join(input_images_dir, image_filename)
        label_path = os.path.join(input_labels_dir, base_name + '.txt')

        # è¯»å–å›¾åƒ (Albumentations éœ€è¦ RGB æ ¼å¼)
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # è¯»å– YOLO æ ‡ç­¾
        bboxes = []
        class_labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id = int(parts[0])
                        coords = [float(p) for p in parts[1:]]
                        bboxes.append(coords)
                        class_labels.append(class_id)

        # ä¸ºæ¯å¼ å›¾ç‰‡ç”Ÿæˆ N ä¸ªå¢å¼ºç‰ˆæœ¬
        for i in range(num_aug_per_image):
            try:
                # åº”ç”¨å˜æ¢
                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)
                aug_image = augmented['image']
                aug_bboxes = augmented['bboxes']

                # å¦‚æœå¢å¼ºåæ‰€æœ‰æ¡†éƒ½æ¶ˆå¤±äº†ï¼Œåˆ™è·³è¿‡æ­¤æ¬¡ä¿å­˜
                if not aug_bboxes:
                    continue

                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                aug_base_name = f"{base_name}_aug_{i}"
                aug_image_path = os.path.join(output_images_dir, aug_base_name + ext)
                aug_label_path = os.path.join(output_labels_dir, aug_base_name + '.txt')

                # ä¿å­˜å¢å¼ºåçš„å›¾åƒ (è½¬å› BGR ä»¥ä¾¿ cv2 ä¿å­˜)
                cv2.imwrite(aug_image_path, cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))

                # ä¿å­˜å¢å¼ºåçš„æ ‡ç­¾
                with open(aug_label_path, 'w') as f:
                    for bbox, class_id in zip(aug_bboxes, augmented['class_labels']):
                        # bbox æ ¼å¼ä¸º [x_center, y_center, width, height]
                        line = f"{class_id} {' '.join(f'{c:.6f}' for c in bbox)}\n"
                        f.write(line)
            except Exception as e:
                print(f"å¤„ç† {image_filename} æ—¶å‡ºé”™ (å¢å¼ºç‰ˆæœ¬ {i}): {e}")

    print("\næ•°æ®å¢å¼ºæµç¨‹å…¨éƒ¨å®Œæˆï¼")
    print(f"ç»“æœå·²ä¿å­˜åœ¨: {os.path.abspath(output_dir)}")


def main():
    parser = argparse.ArgumentParser(description="YOLO Detection Dataset Augmentation Script")
    parser.add_argument('--input', type=str, required=True,
                        help='Path to the input dataset directory.')
    parser.add_argument('--output', type=str, required=True,
                        help='Path to the directory to save the augmented dataset.')
    parser.add_argument('--num', type=int, default=2,
                        help='Number of augmented versions to generate per original image.')

    args = parser.parse_args()

    augment_dataset(args.input, args.output, args.num)


if __name__ == "__main__":
    main()