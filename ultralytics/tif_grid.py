# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
tifå›¾åƒç›®æ ‡æ£€æµ‹è„šæœ¬ï¼Œè¯»å–config.yamlæ–‡ä»¶èŽ·å–å‚æ•°åˆ’åˆ†ç½‘æ ¼å®žçŽ°å¤šçº¿ç¨‹æˆ–æ‰¹å¤„ç†ç›®æ ‡æ£€æµ‹æŽ¨ç†
TIF image object detection script that reads the config.yaml file
to obtain parameters, divides the grid, and implements multiprocessing object detection inference.

usage:
    python tif_grid.py

config.yaml:
    # ------------------- #
    #  æ–‡ä»¶ä¸Žç›®å½•è·¯å¾„
    # ------------------- #
    # è¾“å…¥çš„å¤§åž‹TIFæ–‡ä»¶
    input_tif: 'D:/download/p3.tif'
    # è¾“å‡ºç›®å½•ï¼Œç”¨äºŽå­˜æ”¾æœ€ç»ˆç»“æžœ
    output_dir: 'D:/download/results'
    # ç›®æ ‡æ£€æµ‹æ¨¡åž‹çš„.ptæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚YOLOv5, v7, v8)
    model_path: 'models/blue_v1.pt'

    # ------------------- #
    #  åˆ‡ç‰‡å‚æ•°
    # ------------------- #
    # åˆ‡ç‰‡å°ºå¯¸ (æ­£æ–¹å½¢)
    tile_size: 640
    # åˆ‡ç‰‡é—´çš„é‡å åƒç´ 
    overlap: 16

    # ------------------- #
    #  æ¨¡åž‹æŽ¨ç†å‚æ•°
    # ------------------- #
    # GPUè®¾å¤‡ID (å¦‚æžœä½¿ç”¨CPUï¼Œåˆ™è®¾ä¸º 'cpu')
    device: 'cuda:0' # æˆ–è€… 'cpu'
    # ç›®æ ‡æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼
    conf_threshold: 0.85
    # NMS (éžæžå¤§å€¼æŠ‘åˆ¶) çš„IOUé˜ˆå€¼
    iou_threshold: 0.25
    # æŽ¨ç†æ—¶çš„å›¾åƒå°ºå¯¸ï¼ˆåº”ä¸Žæ¨¡åž‹è®­ç»ƒå°ºå¯¸åŒ¹é…ï¼‰
    inference_img_size: 640

    # ä½¿ç”¨çš„è¿›ç¨‹æ•° (0 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ)
    num_workers: 4

    # ä½¿ç”¨æ‰¹å¤„ç†
    batch_size: 16

"""

import os
import yaml
import time
import torch
import rasterio
import numpy as np
import cv2
import logging
from ultralytics import YOLO
from rasterio.windows import Window
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import torchvision


# --- æ‰“å°é…ç½®ä¿¡æ¯ --- #
def print_config(config, logger):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    logger.info("=" * 50)
    logger.info("æ£€æµ‹é…ç½®å‚æ•°:")
    for key, value in config.items():
        # è·³è¿‡å¯èƒ½çš„å¤§å¯¹è±¡
        if isinstance(value, (list, dict)) and len(str(value)) > 100:
            logger.info(f"{key}: [æ•°æ®è¿‡é•¿ä¸æ˜¾ç¤º]")
        else:
            logger.info(f"{key}: {value}")
    logger.info("=" * 50)


# --- é…ç½®æ—¥å¿—ç³»ç»Ÿ --- #
def setup_logger(output_dir):
    """é…ç½®å¹¶è¿”å›žloggerå¯¹è±¡"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # æ–‡ä»¶å¤„ç†å™¨
    log_file = os.path.join(output_dir, "detected.txt")
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)

    # æŽ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    return logger


def process_chunk_worker(args):
    windows_chunk, config, logger = args
    try:
        device = torch.device(config['device'])
        # åŠ è½½å·²ç»ä¸ºåŠ¨æ€æ‰¹å¤„ç†ä¼˜åŒ–çš„TensorRTå¼•æ“Ž
        model = YOLO(config['model_path'], task="detect")
        class_names = model.names
    except Exception as e:
        return [], f"æ¨¡åž‹åŠ è½½å¤±è´¥äºŽè¿›ç¨‹ {os.getpid()}: {e}"

    local_detections = []

    try:
        src = rasterio.open(config['input_tif'])
    except Exception as e:
        return [], f"rasterio æ‰“å¼€å¤±è´¥äºŽè¿›ç¨‹ {os.getpid()}: {e}"

    try:
        for i in range(0, len(windows_chunk), config['batch_size']):
            batch_windows = windows_chunk[i:i + config['batch_size']]
            batch_images = []
            batch_metas = []

            for window in batch_windows:
                try:
                    # ç›´æŽ¥è¯»å–å¹¶ç¼©æ”¾åˆ° tile_sizeï¼Œå¯å‡å°‘åŽç»­ resize/pad
                    tile_data = src.read(window=window, out_shape=(src.count, config['tile_size'], config['tile_size']))
                    if tile_data is None or tile_data.size == 0:
                        continue

                    img = np.moveaxis(tile_data, 0, -1)
                    if img.shape[2] == 4:
                        img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)
                    elif img.shape[2] > 4:
                        img = img[:, :, :3]

                    if img.dtype != np.uint8:
                        p2, p98 = np.percentile(img, (2, 98))
                        if p98 - p2 > 0:
                            img = np.clip((img - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)
                        else:
                            img = np.zeros_like(img, dtype=np.uint8)

                    if np.max(img) == 0:
                        continue

                    batch_images.append(img)
                    batch_metas.append({'window': window})
                except Exception as tile_e:
                    logger.debug(f"çª—å£ {window} è¯»å–å¤±è´¥: {tile_e}")
                    continue

            if not batch_images:
                continue

            # æŽ¨ç†
            try:
                results = model.predict(batch_images, verbose=False, conf=config['conf_threshold'], iou=config['iou_threshold'], device=device)
                for result, meta in zip(results, batch_metas):
                    dets = result.boxes.data
                    window = meta['window']
                    if dets is not None and len(dets):
                        for *xyxy, conf, cls in reversed(dets):
                            x_min_global = int(xyxy[0]) + window.col_off
                            y_min_global = int(xyxy[1]) + window.row_off
                            x_max_global = int(xyxy[2]) + window.col_off
                            y_max_global = int(xyxy[3]) + window.row_off
                            label_name = class_names[int(cls)]
                            local_detections.append([x_min_global, y_min_global, x_max_global, y_max_global, float(conf), label_name])
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡æŽ¨ç†é”™è¯¯: {e}")
                continue
    finally:
        src.close()
        return local_detections, None


# --- å¤šè¿›ç¨‹æ‰¹å¤„ç†å‡½æ•° --- #
def multiprocess_batch_inference(windows, config, logger):
    """
    å¤šè¿›ç¨‹æ‰¹å¤„ç†å‡½æ•°ã€‚
    å°†çª—å£åˆ—è¡¨åˆ†å‰²æˆå¤šä¸ªåŒºå—ï¼Œæ¯ä¸ªåŒºå—åˆ†é…ç»™ä¸€ä¸ªè¿›ç¨‹è¿›è¡Œæ‰¹å¤„ç†æŽ¨ç†ã€‚
    """
    num_workers = config['num_workers']
    # logger.info(f"æ­¥éª¤ 2/5: ä½¿ç”¨ {num_workers} ä¸ªè¿›ç¨‹è¿›è¡Œå¤šè¿›ç¨‹æ‰¹å¤„ç†æŽ¨ç†...")

    # 1. å°†æ‰€æœ‰çª—å£åˆ†å‰²æˆ num_workers ä¸ªå¤§åŒºå—
    # np.array_split å¯ä»¥å¾ˆå¥½åœ°å¤„ç†ä¸èƒ½å‡åˆ†çš„æƒ…å†µ
    window_chunks = np.array_split(windows, num_workers)

    # ä¸ºæ¯ä¸ªåŒºå—ï¼ˆä»»åŠ¡ï¼‰æ‰“åŒ…å‚æ•°
    tasks = [(chunk.tolist(), config, logger) for chunk in window_chunks if chunk.size > 0]

    all_detections_flat = []
    errors = []

    # 2. åˆ›å»ºè¿›ç¨‹æ± ï¼Œå¹¶å°†æ¯ä¸ªåŒºå—åˆ†é…ç»™ä¸€ä¸ªå·¥ä½œå‡½æ•°
    with Pool(processes=num_workers) as pool:
        # tqdm çš„ total æ˜¯ä»»åŠ¡æ•°ï¼Œå³è¿›ç¨‹æ•°
        results = list(tqdm(pool.imap(process_chunk_worker, tasks), total=len(tasks), desc="å¤šè¿›ç¨‹æ‰¹å¤„ç†è¿›åº¦"))

    # 3. æ”¶é›†å¹¶æ•´ç†æ‰€æœ‰è¿›ç¨‹è¿”å›žçš„ç»“æžœ
    for detections, error in results:
        if error:
            errors.append(error)
        if detections:
            all_detections_flat.extend(detections)

    # è®°å½•é”™è¯¯ä¿¡æ¯
    if errors:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ° {len(errors)} ä¸ªé”™è¯¯:")
        for error in errors:
            logger.error(error)

    return all_detections_flat


# --- ä¸»å‡½æ•° --- #
def main(config, logger):
    """ä¸»å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæŽ¨ç†æµç¨‹"""
    print_config(config, logger)

    # 1. ç”Ÿæˆåˆ‡ç‰‡ç½‘æ ¼
    logger.info("æ­¥éª¤ 1/5: è®¡ç®—åˆ‡ç‰‡ç½‘æ ¼...")
    step = config['tile_size'] - config['overlap']
    windows = []

    with rasterio.open(config['input_tif']) as src:
        image_width, image_height = src.width, src.height
        meta = src.meta.copy()
        for y_off in range(0, image_height, step):
            for x_off in range(0, image_width, step):
                width = min(config['tile_size'], image_width - x_off)
                height = min(config['tile_size'], image_height - y_off)
                windows.append(Window(x_off, y_off, width, height))

    logger.info(f"å®Œæˆã€‚å…±æ‰¾åˆ° {len(windows)} ä¸ªåˆ‡ç‰‡ã€‚")

    # 2. å¤šè¿›ç¨‹æ‰¹å¤„ç†æŽ¨ç†
    logger.info(f"æ­¥éª¤ 2/5: ä½¿ç”¨ {config['num_workers']} ä¸ªè¿›ç¨‹è¿›è¡Œæ‰¹å¤„ç†æŽ¨ç†...")
    all_detections_flat = multiprocess_batch_inference(windows, config, logger)

    logger.info(f"å®Œæˆã€‚æ‰€æœ‰åˆ‡ç‰‡å…±æ£€æµ‹åˆ° {len(all_detections_flat)} ä¸ªåˆæ­¥ç›®æ ‡ã€‚")

    # 3. å…¨å±€éžæžå¤§å€¼æŠ‘åˆ¶ (NMS)
    logger.info("æ­¥éª¤ 3/5: æ‰§è¡Œå…¨å±€éžæžå¤§å€¼æŠ‘åˆ¶ (NMS)...")
    if not all_detections_flat:
        logger.info("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œæµç¨‹ç»“æŸã€‚")
        return

    boxes = torch.tensor([det[:4] for det in all_detections_flat], dtype=torch.float32)
    scores = torch.tensor([det[4] for det in all_detections_flat], dtype=torch.float32)
    indices = torchvision.ops.nms(boxes, scores, config['iou_threshold'])
    final_detections = [all_detections_flat[i] for i in indices]
    logger.info(f"å®Œæˆã€‚NMSåŽå‰©ä½™ {len(final_detections)} ä¸ªå”¯ä¸€ç›®æ ‡ã€‚")

    # 4. åœ¨åŽŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆç»“æžœ
    logger.info("æ­¥éª¤ 4/5: åœ¨åŽŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆè¾¹ç•Œæ¡†å¹¶ä¿å­˜æ£€æµ‹ç›®æ ‡ç»“æžœå›¾...")
    with rasterio.open(config['input_tif']) as src:
        h, w = src.height, src.width
        output_image = np.moveaxis(src.read(), 0, -1).copy()

        # å¤„ç†å¤šé€šé“å›¾åƒ
        if output_image.shape[2] == 4:
            output_image = cv2.cvtColor(output_image, cv2.COLOR_RGBA2RGB)
        elif output_image.shape[2] > 4:
            output_image = output_image[:, :, :3]  # åªå–å‰ä¸‰ä¸ªé€šé“

        # å½’ä¸€åŒ–åˆ°uint8
        if output_image.dtype != np.uint8:
            p2, p98 = np.percentile(output_image, (2, 98))
            output_image = np.clip((output_image - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)

        count = 1
        original_image = output_image.copy()
        output_filename = os.path.basename(config['input_tif'])
        image_dir = os.path.join(config['output_dir'], f"{os.path.splitext(output_filename)[0]}")
        os.makedirs(image_dir, exist_ok=True)

        for x1, y1, x2, y2, conf, label in tqdm(final_detections, desc="ç»˜åˆ¶è¾¹ç•Œæ¡†"):
            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))
            # å®šä¹‰è£å‰ªè¾¹ç•Œå¹¶ç¡®ä¿ä¸è¶Šç•Œ
            crop_x1 = max(0, x1 - 50)
            crop_y1 = max(0, y1 - 50)
            crop_x2 = min(w, x2 + 50)
            crop_y2 = min(h, y2 + 50)

            cropped_img = original_image[crop_y1 : crop_y2, crop_x1 : crop_x2]
            cropped_img= cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)
            # x0, y0 = (x1 + x2) / 2, (y1 + y2) / 2
            cut_image = os.path.join(image_dir, f"{count}.png")
            cv2.imwrite(cut_image, cropped_img)

            crop0_x1 = max(10, x1 - 200)
            crop0_y1 = max(10, y1 - 200)
            crop0_x2 = min(w - 10, x2 + 200)
            crop0_y2 = min(h - 10, y2 + 200)
            cv2.rectangle(output_image, (crop0_x1, crop0_y1), (crop0_x2, crop0_y2), (255, 0, 0), 10)
            label_text = f"{count}: {conf:.2f}"
            cv2.putText(output_image, label_text, (crop0_x1, crop0_y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 10)
            count += 1

    logger.info("å®Œæˆã€‚")

    # 5. ä¿å­˜ç»“æžœ
    logger.info("æ­¥éª¤ 5/5: ä¿å­˜å¸¦æœ‰æ£€æµ‹ç»“æžœçš„TIFå›¾åƒ...")
    output_image_raster = np.moveaxis(output_image, -1, 0)

    # æ›´æ–°å…ƒæ•°æ®
    meta.update({
        'driver': 'GTiff',
        'dtype': 'uint8',
        'count': 3,
        'compress': 'lzw'
    })

    output_filename = os.path.basename(config['input_tif'])
    output_filepath = os.path.join(config['output_dir'], f"{os.path.splitext(output_filename)[0]}_detected.tif")

    with rasterio.open(output_filepath, 'w', **meta) as dst:
        dst.write(output_image_raster)

    logger.info(f"å¤„ç†æˆåŠŸï¼æœ€ç»ˆç»“æžœå·²ä¿å­˜è‡³: {output_filepath}")


if __name__ == '__main__':
    start_time = time.time()

    # åŠ è½½é…ç½®æ–‡ä»¶
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        print("é”™è¯¯: `config.yaml` æœªæ‰¾åˆ°ã€‚è¯·æ ¹æ®æ¨¡æ¿åˆ›å»ºå¹¶é…ç½®è¯¥æ–‡ä»¶ã€‚")
        exit()
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        exit()

    # åŠ¨æ€è®¾ç½®è¿›ç¨‹æ•°
    if config.get('num_workers', 0) == 0:
        config['num_workers'] = cpu_count()

    # è®¾ç½®é»˜è®¤å€¼
    config.setdefault('conf_threshold', 0.25)
    config.setdefault('iou_threshold', 0.85)
    config.setdefault('overlap', 16)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(config['input_tif']):
        print(f"é”™è¯¯: è¾“å…¥çš„TIFæ–‡ä»¶æœªæ‰¾åˆ° -> {config['input_tif']}")
        exit()

    # è®¾ç½®æ—¥å¿—
    os.makedirs(config['output_dir'], exist_ok=True)
    logger = setup_logger(config['output_dir'])

    main(config, logger)

    end_time = time.time()
    logger.info(f"æ€»è€—æ—¶: {(end_time - start_time):.2f} s")