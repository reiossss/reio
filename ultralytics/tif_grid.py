# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
tifå›¾åƒç›®æ ‡æ£€æµ‹è„šæœ¬ï¼Œè¯»å–config.yamlæ–‡ä»¶è·å–å‚æ•°åˆ’åˆ†ç½‘æ ¼å®ç°å¤šçº¿ç¨‹ç›®æ ‡æ£€æµ‹æ¨ç†
TIF image object detection script that reads the config.yaml file
to obtain parameters, divides the grid, and implements multiprocessing object detection inference.

usage:
    python tif_grid.py

config.yaml:
    # ------------------- #
    #  æ–‡ä»¶ä¸ç›®å½•è·¯å¾„
    # ------------------- #
    # è¾“å…¥çš„å¤§å‹TIFæ–‡ä»¶
    input_tif: 'D:\downlord\p2.tif'
    # è¾“å‡ºç›®å½•ï¼Œç”¨äºå­˜æ”¾æœ€ç»ˆç»“æœ
    output_dir: 'D:\downlord\results'
    # ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„.ptæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚YOLOv5, v7, v8)
    model_path: 'models\car_type_v11.pt'

    # ------------------- #
    #  åˆ‡ç‰‡å‚æ•°
    # ------------------- #
    # åˆ‡ç‰‡å°ºå¯¸ (æ­£æ–¹å½¢)
    tile_size: 640
    # åˆ‡ç‰‡é—´çš„é‡å åƒç´ 
    overlap: 16

    # ------------------- #
    #  æ¨¡å‹æ¨ç†å‚æ•°
    # ------------------- #
    # GPUè®¾å¤‡ID (å¦‚æœä½¿ç”¨CPUï¼Œåˆ™è®¾ä¸º 'cpu')
    device: 'cuda:0' # æˆ–è€… 'cpu'
    # ç›®æ ‡æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼
    conf_threshold: 0.4
    # NMS (éæå¤§å€¼æŠ‘åˆ¶) çš„IOUé˜ˆå€¼
    iou_threshold: 0.5
    # æ¨ç†æ—¶çš„å›¾åƒå°ºå¯¸ï¼ˆåº”ä¸æ¨¡å‹è®­ç»ƒå°ºå¯¸åŒ¹é…ï¼‰
    inference_img_size: 640

    # ä½¿ç”¨çš„è¿›ç¨‹æ•° (0 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ)
    num_workers: 4
"""

import os
import yaml
import time
import torch
import rasterio
import numpy as np
import cv2
import logging
from ultralytics import YOLO
from rasterio.windows import Window
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import torchvision


# --- é…ç½®æ—¥å¿—ç³»ç»Ÿ --- #
def setup_logger(output_dir):
    """é…ç½®å¹¶è¿”å›loggerå¯¹è±¡"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # æ–‡ä»¶å¤„ç†å™¨
    log_file = os.path.join(output_dir, 'detection_log.txt')
    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(formatter)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    return logger


# --- æ‰“å°é…ç½®ä¿¡æ¯ --- #
def print_config(config, logger):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    logger.info("=" * 50)
    logger.info("æ£€æµ‹é…ç½®å‚æ•°:")
    for key, value in config.items():
        # è·³è¿‡å¯èƒ½çš„å¤§å¯¹è±¡
        if isinstance(value, (list, dict)) and len(str(value)) > 100:
            logger.info(f"{key}: [æ•°æ®è¿‡é•¿ä¸æ˜¾ç¤º]")
        else:
            logger.info(f"{key}: {value}")
    logger.info("=" * 50)


# --- å·¥ä½œè¿›ç¨‹å‡½æ•° --- #
def process_tile(args):
    """å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼Œç”¨äºåœ¨å•ä¸ªåˆ‡ç‰‡ä¸Šæ‰§è¡Œæ¨ç†"""
    tile_window, config = args
    model = None
    all_detections = []

    try:
        # åœ¨è¿›ç¨‹å†…åŠ è½½æ¨¡å‹
        device = torch.device(config['device'])
        model = YOLO(config['model_path'])
        model.to(device)
        class_names = model.names

        # è¯»å–åˆ‡ç‰‡æ•°æ®
        with rasterio.open(config['input_tif']) as src:
            tile_data = src.read(window=tile_window)

        # å›¾åƒé¢„å¤„ç†
        img = np.moveaxis(tile_data, 0, -1)

        # å¤„ç†å¤šé€šé“å›¾åƒ
        if img.shape[2] == 4:
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
        elif img.shape[2] > 4:
            img = img[:, :, :3]  # åªå–å‰ä¸‰ä¸ªé€šé“

        # å½’ä¸€åŒ–åˆ°uint8
        if img.dtype != np.uint8:
            p2, p98 = np.percentile(img, (2, 98))
            img = np.clip((img - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)

        # æ¨¡å‹æ¨ç†
        results = model(img, verbose=False)
        dets = results[0].boxes.data

        if dets is not None and len(dets):
            for *xyxy, conf, cls in reversed(dets):
                if conf < config['conf_threshold']:
                    continue

                # è½¬æ¢åˆ°å…¨å±€åæ ‡
                x_min_global = int(xyxy[0]) + tile_window.col_off
                y_min_global = int(xyxy[1]) + tile_window.row_off
                x_max_global = int(xyxy[2]) + tile_window.col_off
                y_max_global = int(xyxy[3]) + tile_window.row_off

                label_index = int(cls)
                label_name = class_names[label_index]

                all_detections.append([
                    x_min_global, y_min_global, x_max_global, y_max_global,
                    float(conf), label_name
                ])

    except Exception as e:
        import traceback
        error_msg = f"è¿›ç¨‹ {os.getpid()} åœ¨å¤„ç†åˆ‡ç‰‡ {tile_window} æ—¶å‡ºé”™: {e}\n{traceback.format_exc()}"
        return all_detections, error_msg

    return all_detections, None


# --- ä¸»å‡½æ•° --- #
def main(config):
    """ä¸»å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæ¨ç†æµç¨‹"""
    # è®¾ç½®æ—¥å¿—
    os.makedirs(config['output_dir'], exist_ok=True)
    logger = setup_logger(config['output_dir'])
    print_config(config, logger)

    # 1. ç”Ÿæˆåˆ‡ç‰‡ç½‘æ ¼
    logger.info("æ­¥éª¤ 1/5: è®¡ç®—åˆ‡ç‰‡ç½‘æ ¼...")
    step = config['tile_size'] - config['overlap']
    windows = []

    with rasterio.open(config['input_tif']) as src:
        image_width, image_height = src.width, src.height
        meta = src.meta.copy()
        for y_off in range(0, image_height, step):
            for x_off in range(0, image_width, step):
                width = min(config['tile_size'], image_width - x_off)
                height = min(config['tile_size'], image_height - y_off)
                windows.append(Window(x_off, y_off, width, height))

    logger.info(f"å®Œæˆã€‚å…±æ‰¾åˆ° {len(windows)} ä¸ªåˆ‡ç‰‡ã€‚")

    # 2. å¤šè¿›ç¨‹æ¨ç†
    logger.info(f"æ­¥éª¤ 2/5: ä½¿ç”¨ {config['num_workers']} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œæ¨ç†...")
    all_detections_flat = []
    errors = []
    tasks = [(window, config) for window in windows]

    with Pool(processes=config['num_workers']) as pool:
        results = list(tqdm(pool.imap(process_tile, tasks), total=len(tasks), desc="æ¨ç†è¿›åº¦"))

    for detections, error in results:
        if error:
            errors.append(error)
        if detections:
            all_detections_flat.extend(detections)

    # è®°å½•é”™è¯¯ä¿¡æ¯
    if errors:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ° {len(errors)} ä¸ªé”™è¯¯:")
        for error in errors:
            logger.error(error)

    logger.info(f"å®Œæˆã€‚æ‰€æœ‰åˆ‡ç‰‡å…±æ£€æµ‹åˆ° {len(all_detections_flat)} ä¸ªåˆæ­¥ç›®æ ‡ã€‚")

    # 3. å…¨å±€éæå¤§å€¼æŠ‘åˆ¶ (NMS)
    logger.info("æ­¥éª¤ 3/5: æ‰§è¡Œå…¨å±€éæå¤§å€¼æŠ‘åˆ¶ (NMS)...")
    if not all_detections_flat:
        logger.info("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œæµç¨‹ç»“æŸã€‚")
        return

    boxes = torch.tensor([det[:4] for det in all_detections_flat], dtype=torch.float32)
    scores = torch.tensor([det[4] for det in all_detections_flat], dtype=torch.float32)
    indices = torchvision.ops.nms(boxes, scores, config['iou_threshold'])
    final_detections = [all_detections_flat[i] for i in indices]
    logger.info(f"å®Œæˆã€‚NMSåå‰©ä½™ {len(final_detections)} ä¸ªå”¯ä¸€ç›®æ ‡ã€‚")

    # 4. åœ¨åŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆç»“æœ
    logger.info("æ­¥éª¤ 4/5: åœ¨åŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆè¾¹ç•Œæ¡†...")
    with rasterio.open(config['input_tif']) as src:
        output_image = np.moveaxis(src.read(), 0, -1).copy()

        # å¤„ç†å¤šé€šé“å›¾åƒ
        if output_image.shape[2] == 4:
            output_image = cv2.cvtColor(output_image, cv2.COLOR_RGBA2RGB)
        elif output_image.shape[2] > 4:
            output_image = output_image[:, :, :3]  # åªå–å‰ä¸‰ä¸ªé€šé“

        # å½’ä¸€åŒ–åˆ°uint8
        if output_image.dtype != np.uint8:
            p2, p98 = np.percentile(output_image, (2, 98))
            output_image = np.clip((output_image - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)

        for x1, y1, x2, y2, conf, label in tqdm(final_detections, desc="ç»˜åˆ¶è¾¹ç•Œæ¡†"):
            cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 2)
            label_text = f"{label}: {conf:.2f}"
            cv2.putText(output_image, label_text, (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)

    logger.info("å®Œæˆã€‚")

    # 5. ä¿å­˜ç»“æœ
    logger.info("æ­¥éª¤ 5/5: ä¿å­˜å¸¦æœ‰æ£€æµ‹ç»“æœçš„TIFå›¾åƒ...")
    output_image_raster = np.moveaxis(output_image, -1, 0)

    # æ›´æ–°å…ƒæ•°æ®
    meta.update({
        'driver': 'GTiff',
        'dtype': 'uint8',
        'count': 3,
        'compress': 'lzw'
    })

    output_filename = os.path.basename(config['input_tif'])
    output_filepath = os.path.join(config['output_dir'], f"{os.path.splitext(output_filename)[0]}_detected.tif")

    with rasterio.open(output_filepath, 'w', **meta) as dst:
        dst.write(output_image_raster)

    logger.info(f"å¤„ç†æˆåŠŸï¼æœ€ç»ˆç»“æœå·²ä¿å­˜è‡³: {output_filepath}")


if __name__ == '__main__':
    start_time = time.time()

    # åŠ è½½é…ç½®æ–‡ä»¶
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        print("é”™è¯¯: `config.yaml` æœªæ‰¾åˆ°ã€‚è¯·æ ¹æ®æ¨¡æ¿åˆ›å»ºå¹¶é…ç½®è¯¥æ–‡ä»¶ã€‚")
        exit()
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        exit()

    # åŠ¨æ€è®¾ç½®è¿›ç¨‹æ•°
    if config.get('num_workers', 0) == 0:
        config['num_workers'] = cpu_count()

    # è®¾ç½®é»˜è®¤å€¼
    config.setdefault('conf_threshold', 0.25)
    config.setdefault('iou_threshold', 0.45)
    config.setdefault('overlap', 16)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(config['input_tif']):
        print(f"é”™è¯¯: è¾“å…¥çš„TIFæ–‡ä»¶æœªæ‰¾åˆ° -> {config['input_tif']}")
        exit()

    main(config)

    end_time = time.time()
    print(f"æ€»è€—æ—¶: {(end_time - start_time):.2f} s")