# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
tifå›¾åƒåˆ‡ç‰‡ç›®æ ‡æ£€æµ‹è„šæœ¬ï¼Œè¯»å–config.yamlæ–‡ä»¶è·å–å‚æ•°åˆ’åˆ†ç½‘æ ¼å®ç°å¤šçº¿ç¨‹æ‰¹å¤„ç†ç›®æ ‡æ£€æµ‹æ¨ç†
TIF image object detection script that reads the config.yaml file
to obtain parameters, divides the grid, and implements multiprocessing object detection inference.

usage:
    python tif_grid.py

config.yaml:
    # ------------------- #
    #  æ–‡ä»¶ä¸ç›®å½•è·¯å¾„
    # ------------------- #
    # è¾“å…¥çš„å¤§å‹TIFæ–‡ä»¶
    input_tif: 'D:/downlord/p3.tif'
    # è¾“å‡ºç›®å½•ï¼Œç”¨äºå­˜æ”¾æœ€ç»ˆç»“æœ
    output_dir: 'D:/downlord/results'
    # ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„.ptæ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚YOLOv5, v7, v8)
    model_path: 'models/blue_v1.pt'

    # ------------------- #
    #  åˆ‡ç‰‡å‚æ•°
    # ------------------- #
    # åˆ‡ç‰‡å°ºå¯¸ (æ­£æ–¹å½¢)
    tile_size: 640
    # åˆ‡ç‰‡é—´çš„é‡å åƒç´ 
    overlap: 16

    # ------------------- #
    #  æ¨¡å‹æ¨ç†å‚æ•°
    # ------------------- #
    # GPUè®¾å¤‡ID (å¦‚æœä½¿ç”¨CPUï¼Œåˆ™è®¾ä¸º 'cpu')
    device: 'cuda:0' # æˆ–è€… 'cpu'
    # ç›®æ ‡æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼
    conf_threshold: 0.85
    # NMS (éæå¤§å€¼æŠ‘åˆ¶) çš„IOUé˜ˆå€¼
    iou_threshold: 0.25
    # æ¨ç†æ—¶çš„å›¾åƒå°ºå¯¸ï¼ˆåº”ä¸æ¨¡å‹è®­ç»ƒå°ºå¯¸åŒ¹é…ï¼‰
    inference_img_size: 640

    # ä½¿ç”¨çš„è¿›ç¨‹æ•° (0 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ)
    num_workers: 4

    # ä½¿ç”¨æ‰¹å¤„ç†
    batch_size: 16

"""

import os
import yaml
import time
import torch
import rasterio
import numpy as np
import cv2
import logging
from ultralytics import YOLO
from rasterio.windows import Window
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
import torchvision


# --- æ‰“å°é…ç½®ä¿¡æ¯ --- #
def print_config(config, logger):
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    logger.info("=" * 50)
    logger.info("æ£€æµ‹é…ç½®å‚æ•°:")
    for key, value in config.items():
        # è·³è¿‡å¯èƒ½çš„å¤§å¯¹è±¡
        if isinstance(value, (list, dict)) and len(str(value)) > 100:
            logger.info(f"{key}: [æ•°æ®è¿‡é•¿ä¸æ˜¾ç¤º]")
        else:
            logger.info(f"{key}: {value}")
    logger.info("=" * 50)


# --- é…ç½®æ—¥å¿—ç³»ç»Ÿ --- #
def setup_logger(output_dir):
    """é…ç½®å¹¶è¿”å›loggerå¯¹è±¡"""
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # æ–‡ä»¶å¤„ç†å™¨
    log_file = os.path.join(output_dir, "detected.txt")
    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(formatter)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    return logger


# --- å·¥ä½œè¿›ç¨‹å‡½æ•° --- #
def process_chunk_worker(args):
    """
    å·¥ä½œå‡½æ•°ï¼šç”±æ¯ä¸ªç‹¬ç«‹è¿›ç¨‹æ‰§è¡Œã€‚
    è¯¥å‡½æ•°è´Ÿè´£å¤„ç†ä¸€ä¸ªå¤§åŒºå—ï¼ˆchunkï¼‰çš„çª—å£ï¼Œå¹¶åœ¨å†…éƒ¨è¿›è¡Œæ‰¹å¤„ç†æ¨ç†ã€‚
    """
    windows_chunk, config, logger = args
    # 1. åœ¨æ¯ä¸ªå·¥ä½œè¿›ç¨‹ä¸­ç‹¬ç«‹åŠ è½½æ¨¡å‹
    # è¿™æ˜¯è‡³å…³é‡è¦çš„ï¼Œå› ä¸ºæ¨¡å‹å¯¹è±¡ä¸èƒ½åœ¨è¿›ç¨‹é—´å…±äº«
    try:
        device = torch.device(config['device'])
        model = YOLO(config['model_path']).to(device)
        class_names = model.names
    except Exception as e:
        return [], f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}"

    local_detections = []

    # 2. å¯¹åˆ†é…åˆ°çš„åŒºå—è¿›è¡Œæ‰¹å¤„ç†ï¼Œé€»è¾‘ä¸åŸ batch_inference å‡½æ•°ç›¸åŒ
    for i in range(0, len(windows_chunk), config['batch_size']):
        batch_windows = windows_chunk[i:i + config['batch_size']]
        batch_images = []
        batch_metas = []

        try:
            with rasterio.open(config['input_tif']) as src:
                for window in batch_windows:
                    tile_data = src.read(window=window)
                    img = np.moveaxis(tile_data, 0, -1)

                    if img.shape[2] == 4:
                        img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)
                    elif img.shape[2] > 4:
                        img = img[:, :, :3]

                    if img.dtype != np.uint8:
                        p2, p98 = np.percentile(img, (2, 98))
                        img = np.clip((img - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)

                    # æ£€æŸ¥å›¾åƒæ˜¯å¦å…¨ä¸ºé»‘è‰²ã€‚å¦‚æœæ˜¯ï¼Œåˆ™è·³è¿‡æ­¤çª—å£ã€‚
                    if np.max(img) == 0:
                        continue  # è·³è¿‡å½“å‰å¾ªç¯ï¼Œå¤„ç†ä¸‹ä¸€ä¸ª window

                    meta = {'orig_shape': img.shape[:2], 'window': window}
                    batch_images.append(img)
                    batch_metas.append(meta)

            # --- åœ¨è°ƒç”¨æ¨¡å‹ä¹‹å‰æ£€æŸ¥ batch_images æ˜¯å¦ä¸ºç©º ---
            if not batch_images:
                logger.warning(f"å½“å‰æ‰¹æ¬¡ ({i} åˆ° {i + config['batch_size'] - 1}) æ²¡æœ‰æœ‰æ•ˆå›¾åƒï¼Œè·³è¿‡æ¨ç†ã€‚")
                continue  # å¦‚æœ batch_images ä¸ºç©ºï¼Œåˆ™è·³è¿‡å½“å‰æ‰¹æ¬¡çš„æ¨ç†

            # ä½¿ç”¨ YOLO çš„æ‰¹é‡æ¨ç†æ¥å£
            results = model(batch_images, verbose=False)

            for j, (result, meta) in enumerate(zip(results, batch_metas)):
                dets = result.boxes.data
                window = meta['window']

                if dets is not None and len(dets):
                    for *xyxy, conf, cls in reversed(dets):
                        if conf < config['conf_threshold']:
                            continue

                        x_min_global = int(xyxy[0]) + window.col_off
                        y_min_global = int(xyxy[1]) + window.row_off
                        x_max_global = int(xyxy[2]) + window.col_off
                        y_max_global = int(xyxy[3]) + window.row_off

                        label_name = class_names[int(cls)]

                        local_detections.append([
                            x_min_global, y_min_global, x_max_global, y_max_global,
                            float(conf), label_name
                        ])
        except Exception as e:
            # è¿”å›é”™è¯¯ï¼Œä½†å…è®¸å…¶ä»–æ‰¹æ¬¡ç»§ç»­
            logger.error(f"å¤„ç†æ‰¹æ¬¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ‰¹æ¬¡

    return local_detections, None  # è¿”å›æ£€æµ‹ç»“æœå’Œç©ºé”™è¯¯


# --- å¤šè¿›ç¨‹æ‰¹å¤„ç†å‡½æ•° --- #
def multiprocess_batch_inference(windows, config, logger):
    """
    å¤šè¿›ç¨‹æ‰¹å¤„ç†å‡½æ•°ã€‚
    å°†çª—å£åˆ—è¡¨åˆ†å‰²æˆå¤šä¸ªåŒºå—ï¼Œæ¯ä¸ªåŒºå—åˆ†é…ç»™ä¸€ä¸ªè¿›ç¨‹è¿›è¡Œæ‰¹å¤„ç†æ¨ç†ã€‚
    """
    num_workers = config['num_workers']
    # logger.info(f"æ­¥éª¤ 2/5: ä½¿ç”¨ {num_workers} ä¸ªè¿›ç¨‹è¿›è¡Œå¤šè¿›ç¨‹æ‰¹å¤„ç†æ¨ç†...")

    # 1. å°†æ‰€æœ‰çª—å£åˆ†å‰²æˆ num_workers ä¸ªå¤§åŒºå—
    # np.array_split å¯ä»¥å¾ˆå¥½åœ°å¤„ç†ä¸èƒ½å‡åˆ†çš„æƒ…å†µ
    window_chunks = np.array_split(windows, num_workers)

    # ä¸ºæ¯ä¸ªåŒºå—ï¼ˆä»»åŠ¡ï¼‰æ‰“åŒ…å‚æ•°
    tasks = [(chunk.tolist(), config, logger) for chunk in window_chunks if chunk.size > 0]

    all_detections_flat = []
    errors = []

    # 2. åˆ›å»ºè¿›ç¨‹æ± ï¼Œå¹¶å°†æ¯ä¸ªåŒºå—åˆ†é…ç»™ä¸€ä¸ªå·¥ä½œå‡½æ•°
    with Pool(processes=num_workers) as pool:
        # tqdm çš„ total æ˜¯ä»»åŠ¡æ•°ï¼Œå³è¿›ç¨‹æ•°
        results = list(tqdm(pool.imap(process_chunk_worker, tasks), total=len(tasks), desc="å¤šè¿›ç¨‹æ‰¹å¤„ç†è¿›åº¦"))

    # 3. æ”¶é›†å¹¶æ•´ç†æ‰€æœ‰è¿›ç¨‹è¿”å›çš„ç»“æœ
    for detections, error in results:
        if error:
            errors.append(error)
        if detections:
            all_detections_flat.extend(detections)

    # è®°å½•é”™è¯¯ä¿¡æ¯
    if errors:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ° {len(errors)} ä¸ªé”™è¯¯:")
        for error in errors:
            logger.error(error)

    return all_detections_flat


# --- ä¸»å‡½æ•° --- #
def main(config, logger):
    """ä¸»å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæ¨ç†æµç¨‹"""
    print_config(config, logger)

    # 1. ç”Ÿæˆåˆ‡ç‰‡ç½‘æ ¼
    logger.info("æ­¥éª¤ 1/5: è®¡ç®—åˆ‡ç‰‡ç½‘æ ¼...")
    step = config['tile_size'] - config['overlap']
    windows = []

    with rasterio.open(config['input_tif']) as src:
        image_width, image_height = src.width, src.height
        meta = src.meta.copy()
        for y_off in range(0, image_height, step):
            for x_off in range(0, image_width, step):
                width = min(config['tile_size'], image_width - x_off)
                height = min(config['tile_size'], image_height - y_off)
                windows.append(Window(x_off, y_off, width, height))

    logger.info(f"å®Œæˆã€‚å…±æ‰¾åˆ° {len(windows)} ä¸ªåˆ‡ç‰‡ã€‚")

    # 2. å¤šè¿›ç¨‹æ‰¹å¤„ç†æ¨ç†
    logger.info(f"æ­¥éª¤ 2/5: ä½¿ç”¨ {config['num_workers']} ä¸ªè¿›ç¨‹è¿›è¡Œæ‰¹å¤„ç†æ¨ç†...")
    all_detections_flat = multiprocess_batch_inference(windows, config, logger)

    logger.info(f"å®Œæˆã€‚æ‰€æœ‰åˆ‡ç‰‡å…±æ£€æµ‹åˆ° {len(all_detections_flat)} ä¸ªåˆæ­¥ç›®æ ‡ã€‚")

    # 3. å…¨å±€éæå¤§å€¼æŠ‘åˆ¶ (NMS)
    logger.info("æ­¥éª¤ 3/5: æ‰§è¡Œå…¨å±€éæå¤§å€¼æŠ‘åˆ¶ (NMS)...")
    if not all_detections_flat:
        logger.info("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œæµç¨‹ç»“æŸã€‚")
        return

    boxes = torch.tensor([det[:4] for det in all_detections_flat], dtype=torch.float32)
    scores = torch.tensor([det[4] for det in all_detections_flat], dtype=torch.float32)
    indices = torchvision.ops.nms(boxes, scores, config['iou_threshold'])
    final_detections = [all_detections_flat[i] for i in indices]
    logger.info(f"å®Œæˆã€‚NMSåå‰©ä½™ {len(final_detections)} ä¸ªå”¯ä¸€ç›®æ ‡ã€‚")

    # 4. åœ¨åŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆç»“æœ
    logger.info("æ­¥éª¤ 4/5: åœ¨åŸå›¾ä¸Šç»˜åˆ¶æœ€ç»ˆè¾¹ç•Œæ¡†å¹¶ä¿å­˜æ£€æµ‹ç›®æ ‡ç»“æœå›¾...")
    with rasterio.open(config['input_tif']) as src:
        h, w = src.height, src.width
        output_image = np.moveaxis(src.read(), 0, -1).copy()

        # å¤„ç†å¤šé€šé“å›¾åƒ
        if output_image.shape[2] == 4:
            output_image = cv2.cvtColor(output_image, cv2.COLOR_RGBA2RGB)
        elif output_image.shape[2] > 4:
            output_image = output_image[:, :, :3]  # åªå–å‰ä¸‰ä¸ªé€šé“

        # å½’ä¸€åŒ–åˆ°uint8
        if output_image.dtype != np.uint8:
            p2, p98 = np.percentile(output_image, (2, 98))
            output_image = np.clip((output_image - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)

        count = 1
        original_image = output_image.copy()
        output_filename = os.path.basename(config['input_tif'])
        image_dir = os.path.join(config['output_dir'], f"{os.path.splitext(output_filename)[0]}")
        os.makedirs(image_dir, exist_ok=True)

        for x1, y1, x2, y2, conf, label in tqdm(final_detections, desc="ç»˜åˆ¶è¾¹ç•Œæ¡†"):
            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))
            # å®šä¹‰è£å‰ªè¾¹ç•Œå¹¶ç¡®ä¿ä¸è¶Šç•Œ
            crop_x1 = max(0, x1 - 50)
            crop_y1 = max(0, y1 - 50)
            crop_x2 = min(w, x2 + 50)
            crop_y2 = min(h, y2 + 50)

            cropped_img = original_image[crop_y1 : crop_y2, crop_x1 : crop_x2]
            cropped_img= cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)
            # x0, y0 = (x1 + x2) / 2, (y1 + y2) / 2
            cut_image = os.path.join(image_dir, f"{count}.png")
            count += 1
            cv2.imwrite(cut_image, cropped_img)

            crop0_x1 = max(10, x1 - 200)
            crop0_y1 = max(10, y1 - 200)
            crop0_x2 = min(w - 10, x2 + 200)
            crop0_y2 = min(h - 10, y2 + 200)
            cv2.rectangle(output_image, (crop0_x1, crop0_y1), (crop0_x2, crop0_y2), (255, 0, 0), 10)
            label_text = f"{label}: {conf:.2f}"
            cv2.putText(output_image, label_text, (crop0_x1, crop0_y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 10)

    logger.info("å®Œæˆã€‚")

    # 5. ä¿å­˜ç»“æœ
    logger.info("æ­¥éª¤ 5/5: ä¿å­˜å¸¦æœ‰æ£€æµ‹ç»“æœçš„TIFå›¾åƒ...")
    output_image_raster = np.moveaxis(output_image, -1, 0)

    # æ›´æ–°å…ƒæ•°æ®
    meta.update({
        'driver': 'GTiff',
        'dtype': 'uint8',
        'count': 3,
        'compress': 'lzw'
    })

    output_filename = os.path.basename(config['input_tif'])
    output_filepath = os.path.join(config['output_dir'], f"{os.path.splitext(output_filename)[0]}_detected.tif")

    with rasterio.open(output_filepath, 'w', **meta) as dst:
        dst.write(output_image_raster)

    logger.info(f"å¤„ç†æˆåŠŸï¼æœ€ç»ˆç»“æœå·²ä¿å­˜è‡³: {output_filepath}")


if __name__ == '__main__':
    start_time = time.time()

    # åŠ è½½é…ç½®æ–‡ä»¶
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        print("é”™è¯¯: `config.yaml` æœªæ‰¾åˆ°ã€‚è¯·æ ¹æ®æ¨¡æ¿åˆ›å»ºå¹¶é…ç½®è¯¥æ–‡ä»¶ã€‚")
        exit()
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        exit()

    # åŠ¨æ€è®¾ç½®è¿›ç¨‹æ•°
    if config.get('num_workers', 0) == 0:
        config['num_workers'] = cpu_count()

    # è®¾ç½®é»˜è®¤å€¼
    config.setdefault('conf_threshold', 0.25)
    config.setdefault('iou_threshold', 0.85)
    config.setdefault('overlap', 16)

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(config['input_tif']):
        print(f"é”™è¯¯: è¾“å…¥çš„TIFæ–‡ä»¶æœªæ‰¾åˆ° -> {config['input_tif']}")
        exit()

    # è®¾ç½®æ—¥å¿—
    os.makedirs(config['output_dir'], exist_ok=True)
    logger = setup_logger(config['output_dir'])

    main(config, logger)

    end_time = time.time()
    logger.info(f"æ€»è€—æ—¶: {(end_time - start_time):.2f} s")